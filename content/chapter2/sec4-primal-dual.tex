\section{联邦学习中的原始对偶算法}
\addcontentsline{toe}{section}{{2.4\ \ Primal-Dual Algorithms in Federated Learning}\numberline\,}
\label{sec:chap2-primal-dual}

% almost finished

在传统的最优化方法中，原始-对偶算法(Primal-Dual Algorithms)也是一类常用的算法。我们考虑格式为~\eqref{eq:fl-basic-constraint}~的带等式线性约束的共识优化问题(注意与~\eqref{eq:fl-basic-constraint}~的细微差别)
\begin{equation}
\label{eq:fedpd-constraint}
\begin{array}{cl}
\minimize & F(\Theta) := \sum\limits_{k=1}^K f_k(\theta_k), \\
\text{subject to} & \theta_k = \theta, ~ k = 1, \ldots, K.
\end{array}
\end{equation}
其中$\Theta = \col(\theta_1, \cdots, \theta_K), ~ \theta, \theta_1, \ldots, \theta_K \in \R^d.$ 约束优化问题~\eqref{eq:fedpd-constraint}~的增广拉格朗日函数(Augmented Lagrangian, AL)为
\begin{equation}
\label{eq:al}
\mathcal{L}(\theta, \Theta, \Lambda) = F(\Theta) - \sum\limits_{k=1}^K \left\{ \langle \lambda_k, \theta_k \rangle + \frac{1}{2s} \lVert \theta_k - \theta \rVert^2 \right\} = \sum\limits_{k=1}^K \mathcal{L}_k(\theta, \theta_k, \lambda_k)
\end{equation}
其中
\begin{equation}
\label{eq:al-local}
\mathcal{L}_k(\theta, \theta_k, \lambda_k) = f_k(\theta_k) + \langle \lambda_k, \theta_k - \theta \rangle + \frac{1}{2s} \lVert \theta_k - \theta \rVert^2,
\end{equation}
$\Lambda = \col(\lambda_1, \ldots, \lambda_K)$被称作对偶变量(Dual Variable)或者拉格朗日乘子(Lagrangian Multiplier)。通过将梯度提升算法应用到对偶问题
\begin{equation}
\label{eq:al-dual}
\text{maximize} \quad G(\Lambda) := \inf\limits_{\theta, \Theta} \mathcal{L}(\theta, \Theta, \Lambda)
\end{equation}
可以得到解这种形式的问题算法的一般迭代格式
\begin{subequations}
\label{eq:al-iter}
\begin{align}
\theta_k^{(t+1)} & = \argmin_{\theta_k} \mathcal{L}_k(\theta^{(t)}, \theta_k, \lambda_k^{(t)}) \label{eq:al-iter-local} \\
\lambda_k^{(t+1)} & = \lambda_k^{(t)} + \frac{1}{s} (\theta_k^{(t+1)} - \theta^{(t)}) \label{eq:al-iter-dual} \\
\theta^{(t+1)} & = \argmin_{\theta} \sum\limits_{k=1}^K \left\{ \frac{1}{2s} \lVert \theta_k^{(t+1)} - \theta \rVert^2 - \langle \lambda_k^{(t+1)}, \theta \rangle \right\} \nonumber \\
& = \frac{1}{K} \sum\limits_{k=1}^K (\theta_k^{(t+1)} + s\lambda_k^{(t+1)}) \label{eq:al-iter-global}
\end{align}
\end{subequations}

基于这种迭代格式，文献\parencite{zhang2020fedpd}设计了联邦原始对偶(Federated Primal-Dual)算法\texttt{FedPD}，其伪代码可见算法~\ref{algo:fedpd}。

\input{algorithms/fedpd}

联邦原始对偶算法\texttt{FedPD}有以下几点是值得注意的。

首先，在子节点执行本地模型更新，也就是求解问题~\eqref{eq:al-iter-local}~时，\texttt{FedPD}采用了比较灵活的设置，即允许子节点上的求解器
\begin{equation*}
\operatorname{\mathbf{Oracle}}_k(\mathcal{L}_k(\theta_{k, 0}^{(t)}, \theta_k, \lambda_k^{(t)}), \theta_k^{(t)})
\end{equation*}
可以是任何一个求解算法，例如随机梯度下降，亦或是与在SCAFFOLD算法~\ref{algo:scaffold}~中应用过的方差缩减技术进行结合。这种灵活性，是联邦学习的显著特点，这一点我们已经在\S\ref{sec:chap2-overview}~中介绍\texttt{FedOpt}算法的时候已经强调过了。文献\parencite{zhang2020fedpd}进一步特别提到的是，在方差缩减技术的时候，可以进一步结合线性化的方法进行加速,即把需要优化的(局部)拉格朗日函数进行线性化，或者更准确的说，是将$f_k$在$\theta_{k}^{(t,r)}$处线性化：
\begin{equation*}
\begin{aligned}
\widetilde{\mathcal{L}}(\theta_{k}) & := \mathcal{L}_k(\theta_{k, 0}^{(t)}, \theta_k, \lambda_k^{(t)}) = f_k(\theta_k) + \langle \lambda_k^{(t)}, \theta_k - \theta_{k, 0}^{(t)} \rangle + \frac{1}{2s} \lVert \theta_k - \theta_{k, 0}^{(t)} \rVert^2 \\
& = f_k(\theta_k^{(t,r)}) + \langle g_k^{(t,r)}, \theta_k - \theta_k^{(t,r)} \rangle + \frac{1}{2\gamma} \lVert \theta_k - \theta_k^{(t,r)} \rVert^2 + \langle \lambda_k^{(t)}, \theta_k - \theta_{k, 0}^{(t)} \rangle + \frac{1}{2s} \lVert \theta_k - \theta_{k, 0}^{(t)} \rVert^2 \\
& = (\frac{1}{2\gamma} + \frac{1}{2s}) \lVert \theta_k \rVert^2 + \langle g_k^{(t,r)} + \lambda_k^{(t)} - \frac{1}{\gamma} \theta_k^{(t,r)} - \frac{1}{s} \theta_{k, 0}^{(t)}, \theta_k \rangle + \text{const},
\end{aligned}
\end{equation*}
其中$\text{const}$是与$\theta_k$无关的``常量''，$\theta_{k}^{(t,r)}$是内循环，即子节点上的迭代求解的第$r$步得到的值，$g_k^{(t,r)}$是$f_k$在该处的梯度值。由上式可知，$\argmin \widetilde{\mathcal{L}}(\theta_{k})$有解析解
\begin{equation*}
\argmin \widetilde{\mathcal{L}}(\theta_{k}) = \frac{s}{s+\gamma} \theta_k^{(t,r)} + \frac{\gamma}{s+\gamma} \theta_{k, 0}^{(t)} - \frac{s\gamma}{s+\gamma}(g_k^{(t,r)} + \lambda_k^{(t)}).
\end{equation*}

其次，是``跳步''更新技术的使用。我们可以看到，在联邦原始对偶算法 FedPD~\ref{algo:fedpd}~中，外循环以大小为$p$的概率被跳过，也就是说，在迭代格式~\eqref{eq:al-iter}~中，迭代步~\eqref{eq:al-iter-global}~有概率$p$不执行。在前一个循环的迭代步~\eqref{eq:al-iter-global}~不执行的情况下，迭代步~\eqref{eq:al-iter-local}~以及~\eqref{eq:al-iter-dual}~中的$\theta^{(t)}$实际上是$\theta_k^{(t)} + s \lambda_k^{(t)},$ 也就是说联邦原始对偶算法 FedPD~\ref{algo:fedpd}~的迭代格式实际上是
\begin{subequations}
\label{eq:fedpd-iter}
\begin{align}
\theta_k^{(t+1)} & = \argmin_{\theta_k} \mathcal{L}_k(\widetilde{\theta}^{(t)}, \theta_k, \lambda_k^{(t)}) \label{eq:fedpd-iter-local} \\
\lambda_k^{(t+1)} & = \lambda_k^{(t)} + \frac{1}{s} (\theta_k^{(t+1)} - \widetilde{\theta}^{(t)}) \label{eq:fedpd-iter-dual} \\
\theta^{(t+1)} & = \begin{cases}
\frac{1}{K} \sum\limits_{k=1}^K (\theta_k^{(t+1)} + s\lambda_k^{(t+1)}), & \text{概率$1-p$} \\
\theta^{(t)}, & \text{概率$p$}
\end{cases}
\label{eq:fedpd-iter-global}
\end{align}
\end{subequations}
其中
\begin{equation*}
\widetilde{\theta}^{(t)} = \begin{cases}
\theta_k^{(t-1)} + s \lambda_k^{(t-1)}, & \text{若$\theta^{(t)}=\theta^{(t-1)}$} \\
\theta^{(t)}, & \text{其余情况}
\end{cases}
\end{equation*}

跳步更新的方式在提高联邦学习算法的通信效率上有非常明显的优势，而我们已经在\S\ref{sec:chap1-fl-applications}~中介绍过了，通信效率恰恰是大部分联邦学习问题的瓶颈所在。文献~\parencite[TABLE III]{zhang2020fedpd}~进一步给出了跳步更新概率$p$与节点间数据分布异质程度的关系
\begin{equation*}
p \approx \begin{cases}
\sqrt{\frac{1}{36s} \cdot \frac{\varepsilon}{G^2}}, & \text{当$0 \leqslant p < \frac{1-2Ls}{1+Ls},$} \\
1 - 2 / \log(\frac{1}{42s} \cdot \frac{\varepsilon}{G^2}), & \text{当$\frac{1-2Ls}{1+Ls} < p < 1,$}
\end{cases}
\end{equation*}
其中$\varepsilon$是算法收敛点精度相关的常值($\varepsilon$-稳定点)，$G$是通过梯度差异有界性~\eqref{eq:bdd_grad_dissim}~表达的节点间数据分布异质程度的常值，$L$是目标函数$f, f_k$的Lipschitz常数(见式~\eqref{eq:l-smooth})，步长$s$被取定为$s = \frac{\sqrt{5}-1}{8L}.$
