\section{联邦学习中的临近点算法}
\addcontentsline{toe}{section}{{2.2\ \ Proximal Point Algorithms in Federated Learning}\numberline\,}
\label{sec:chap2-ppa}

基于减小数据非独立同分布情形下，每一轮的子节点更新对整体模型的影响，文献\parencite{sahu2018fedprox}首先提在子节点上的局部模型中增加邻近项的\texttt{FedProx}算法，达到了算法收敛更快、更加稳定的目的。具体来说，在算法迭代的第$t+1$轮，每个子节点优化的目标函数从$f_k(\theta_k)$变为了如下的带临近项的函数
\begin{equation}
\label{eq:fedprox}
h_k(\theta_k, \theta^{(t)}) := f_k(\theta_k) + \frac{\mu}{2} \lVert \theta_k - \theta^{(t)} \rVert^2,
\end{equation}
上式中的$\mu$被称作罚参数(penalty constant)。值得注意的是，上式临近项的中心为$\theta^{(t)},$ 即上一轮迭代得到的全局模型。关于临近项中心的其他选取，文献\parencite{hanzely2020federated,li_2021_ditto}进行了研究，我们随后进行详细介绍。我们将\texttt{FedProx}的伪代码总结在算法\ref{algo:fedprox}中。

\input{algorithms/fedprox}

我们把$\gamma$-非精确解$\theta_k^{(t)}$记作
\begin{equation*}
\theta_k^{(t)} \approx \prox_{f_k, \mu} (\theta^{(t)}) := \argmin\limits_{\theta_k} f_k(\theta_k) + \frac{\mu}{2} \lVert \theta_k - \theta^{(t)} \rVert^2,
\end{equation*}
其中的$\prox_{f_k, \mu}$记为所谓的临近算子(proximity operator)。关于\texttt{FedProx}算法在非凸情况下的收敛性，\parencite{sahu2018fedprox}有如下的结论
\begin{theorem}[\parencite{sahu2018fedprox} Theorem 4]
\label{thm:fedprox}
假设子节点的目标函数$\{f_k\}_{k=1}^K$都是非凸、$L$−光滑(定义见式\eqref{eq:l-smooth})函数，并且存在常数$L_- > 0,$使得$\nabla^2 f_k \succcurlyeq -L_- I_d.$ 又假设$\{f_k\}_{k=1}^K$满足差异有解条件(Bounded Dissimilarity)，即对$\varepsilon > 0,$ 存在常数$B_{\varepsilon} > 0,$ 使得集合$\mathcal{S}_{\varepsilon}^c := \{ \theta ~|~ \lVert \nabla f(\theta) \rVert^2 > \varepsilon\}$中的任何一点$\theta$都满足不等式
\begin{equation}
\label{eq:fedprox_bdd_dissim}
B(\theta) := \frac{\expectation_k [\lVert \nabla f_k(\theta) \rVert^2]}{\lVert \nabla f(\theta) \rVert^2} \leqslant B_{\varepsilon}.
\end{equation}
选取常数$\mu, \gamma$满足
\begin{equation*}
\rho := \left( \frac{1}{\mu} - \frac{\gamma B}{\mu} - \frac{B(1+\gamma)\sqrt{2}}{\bar{\mu}\sqrt{K}} - \frac{LB(1+\gamma)}{\bar{\mu}\mu} - \frac{LB^2(1+\gamma)^2}{2\bar{\mu}^2} - \frac{LB^2(1+\gamma)^2}{\bar{\mu}^2 K} \left( 2\sqrt{2K} + 2 \right) \right) > 0,
\end{equation*}
其中$\bar{\mu} = \mu - L_- > 0.$ 那么在算法\ref{algo:fedprox}的第$t+1$步，设前一步的全局模型参数$\theta^{(t)}$为全局目标函数$f$的一阶非稳定点(即$\theta^{(t)} \in \mathcal{S}_{\varepsilon}^c,$ 那么$f$的值满足如下的下降关系
\begin{equation*}
\expectation\nolimits_{\mathcal{S}^{(t)}}[f(\theta^{(t+1)})] \leqslant f(\theta^{(t)}) - \rho \lVert \nabla f (\theta^{(t)}) \rVert^2.
\end{equation*}
\end{theorem}

\begin{rem}
对于\texttt{FedProx}算法收敛性定理\ref{thm:fedprox}，我们有如下的观察：在$\lVert \nabla f \rVert$的零点附近，如果这个零点没有被$\mathbb{E}_k[\lVert \nabla f_k \rVert]$消除掉，即这个点也是$\mathbb{E}_k[\lVert \nabla f_k \rVert]$的零点，且零点的阶数相同，那么在这个点的邻域内，$B_{\varepsilon}$会随着$\varepsilon \to 0$而急速趋向于无穷，导致在$\lVert \nabla f \rVert$的零点附近，$\rho > 0$的假设不再成立，那么定理中的不等式就变得无意义。

当子节点之间的数据分布完全一致的时候（理想情况下），$B_{\varepsilon}$恒为1，就不会有这个问题。这也是后续一系列文章\cite{pathak2020fedsplit,tran2021feddr}进行改进的出发点。
\end{rem}

\texttt{FedProx}算法的积极意义在于，首次将临近点算法(Proximal Point Algorithms, PPA)引入联邦学习领域中。临近点算法不仅仅在理论分析上可以提供一个好的框架，在算法设计上也能提供一个支撑。

文献\parencite{li_2021_ditto}进一步发展了\texttt{FedProx}\cite{sahu2018fedprox}添加临近项的思想，将子节点的优化问题\eqref{eq:fedprox}改进为一个双层优化问题
\begin{equation}
\label{eq:ditto}
\begin{array}{cl}
\minimize & h_k(\theta_k, \omega^*) := f_k(\theta_k) + \frac{\mu}{2} \lVert \theta_k - \omega^* \rVert^2, \\
\text{subject to} & \omega^* \in \argmin_{\omega} G(f_1(\omega)， \cdots, f_K(\omega)),
\end{array}
\end{equation}
其中$G$是中心节点上执行子节点模型参数聚合的函数，例如\texttt{FedAvg}算法中采用的求均值函数。
