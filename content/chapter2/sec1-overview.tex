\section{联邦学习中的优化算法}
\addcontentsline{toe}{section}{{2.1\ \ Overview of Optimization Algorithms in Federated Learning}\numberline\,}
\label{sec:chap2-overview}

优化算法自从联邦学习这一概念诞生起，便一直是相关研究的中心问题之一。联邦学习开创性的文献\parencite{mcmahan2017fed_avg}中，最重要也是最为人所熟知的便是优化算法\texttt{FederatedAveraging}（简记为\texttt{FedAvg}）的提出。这种算法的核心思想，是充分利用子节点的计算能力，在执行完一定轮数的随机梯度下降(Stochastic Gradient Descent, SGD)之后，由中心节点收集各子节点发送过来的模型参数，进行平均(Averaging)，之后再将平均之后的模型参数广播(Broadcast)给子节点进行下一轮迭代。这样，规避了每一轮SGD都进行通信带来的巨大的通信开销，在加速模型训练的同时，数值上在某些情况下还有更好的收敛性。这实际上是一种比较朴素与简单的``跳步''的思想，这种思想也在随后的研究\cite{zhang2020fedpd, proxskip, proxskip-vr}也得到了进一步的发展。

联邦学习优化算法最重要的设计原则，是计算效率以及通信效率并重，甚至很多时候通信效率是更重要的一个方面。这也是联邦学习与传统的分布式优化(Distributed Optimization)最显著的区别之一。实际上，分布式优化在联邦学习被提出之前就是一个被研究得比较多的问题，从具体的问题，例如分布式主成分分析(Principal Component Analysis, PCA)\cite{dist_pca_2014_nips}，到一般的算法理论\cite{boyd2011distributed}都有研究人员进行了研究。当时这些研究往往仅从计算效率以及效果出发，往往不考虑通信效率、通信保密性等问题。文献\parencite{mcmahan2017fed_avg}正是从实际问题出发，发现了这些需求，基于一种分布式梯度下降算法\cite{chen2016_revisit}(该算法在文献\parencite{mcmahan2017fed_avg}中被称作\texttt{FedSGD}算法)，做了上文提到的改进而提出了\texttt{FedAvg}算法。

这里还需要强调的是，\texttt{FedAvg}相对于\texttt{FedSGD}的另一个关键的改进是，子节点与中心节点之间传输的信息，从梯度改为了模型参数。这在某种程度上规避了从梯度泄露联邦学习参与方私密训练数据\cite{zhu2019deep_leakage}的潜在风险。

沿用式\eqref{eq:general-hfl}中的记号，本文考虑联邦学习中的优化问题，其最基本的格式如下
\begin{equation}
\label{eq:fl-basic-dist}
\begin{array}{cl}
\minimize\limits_{\theta \in \R^d} & f(\theta) = \expectation\limits_{k \sim {\mathcal{P}}} [f_k(\theta)], \\
\text{where} & f_k(\theta) = \expectation\limits_{(x, y) \sim \mathcal{D}_k} [\ell_k(\theta; x, y)],
\end{array}
\end{equation}
假设我们令$\mathcal{P} = \{1, 2, \ldots, K\},$ 则上述模型可以简记为
\begin{equation}
\label{eq:fl-basic}
\begin{array}{cl}
\minimize\limits_{\theta \in \R^d} & f(\theta) = \sum\limits_{k=1}^K w_k f_k(\theta).
\end{array}
\end{equation}
对于$f$以及$f_k,$ 我们一般都假设它满足如下几条最基本的性质
\begin{itemize}
\item[(A1)] $f$以及$f_k$都是$L-$光滑的($L-$smooth)，即
\begin{equation}
\label{eq:l-smooth}
\begin{array}{c}
\lVert \nabla f (\theta) - f (\theta') \rVert \leqslant L \lVert \theta - \theta' \rVert, \\
\lVert \nabla f_k (\theta) - f_k (\theta') \rVert \leqslant L \lVert \theta - \theta' \rVert,
\end{array}
~ \forall \theta, \theta' \in \R^d, k = 1, \ldots, K.
\end{equation}
\item[(A2)] $f$下有界(Lower Bounded)：存在常数$c \in \R,$ 使得
\begin{equation}
\label{eq:lower-bounded}
f(\theta) \geqslant c > -\infty, ~ \forall \theta \in \R^d.
\end{equation}
\end{itemize}
很多时候，为了方便收敛性的分析，我们还会对目标函数的梯度进行一些假设
\begin{itemize}
\item[(A3)] 梯度有界性(Bounded Gradient)：存在常数$G > 0,$ 使得
\begin{equation}
\label{eq:bdd_grad}
\lVert \nabla f_k (\theta) \rVert^2 \leqslant G^2, ~ \forall \theta \in \R^d, ~ k = 1, \ldots K.
\end{equation}
\end{itemize}
数据分布的特征(是否独立同分布，以及非独立同分布的程度)是联邦学习避免不了要考虑的问题，这也是联邦学习区别于传统的分布式优化的重要特征，这也是我们在\S\ref{sec:chap1-fl-applications}~中着重讨论过的问题。
\begin{itemize}
\item[(A4-1)] 数据独立同分布(I.I.D.)：
\begin{equation}
\label{eq:iid-1}
\expectation\limits_{(x, y) \sim \mathcal{D}_k}[\nabla \ell_k(\theta; x, y)] = \nabla f(\theta), ~ \forall \theta \in \R^d, ~ k = 1, \ldots K,
\end{equation}
% 或者
% \begin{equation}
% \label{eq:iid-2}
% \sum\limits_{k=1}^K \expectation\limits_{(x, y) \sim \mathcal{D}_k}[\nabla f_k(\theta; x, y)] = \nabla f(\theta), \forall \theta \in \R^d, ~ k = 1, \ldots K,
% \end{equation}
\item[(A4-2)] 数据非独立同分布(Non-I.I.D.)，这个时候我们需要有一个量，用来度量这种统计上的异质性的程度。这个量可以有多种定义方式，本文采用文献\parencite{karimireddy2020scaffold}以及文献\cite{zhang2020fedpd}中定义的梯度差异有界性(Bounded Gradient Dissimilarity)，记作$(G; B)$-BGD. 具体来说，存在常数$G > 0,$ 以及$B \geqslant 0,$ 满足
\begin{equation}
\label{eq:bdd_grad_dissim}
\dfrac{1}{K} \sum\limits_{k=1}^K \lVert \nabla f_k(\theta) \rVert^2 \leqslant G^2 + B^2 \lVert \nabla f(\theta) \rVert^2, ~ \forall \theta \in \R^d.
\end{equation}
需要注意的是，如果令$B = 0,$ 那么梯度差异有界性条件\eqref{eq:bdd_grad_dissim}就退化为了梯度有界性条件\eqref{eq:bdd_grad}。
\end{itemize}

更方便以及自然的做法，是将问题\eqref{eq:fl-basic}写成约束优化问题的格式：
\begin{equation}
\label{eq:fl-basic-constraint}
\begin{array}{cl}
\begin{array}{cl}
\minimize\limits_{\theta \in \R^d} & f(\theta) = \sum\limits_{k=1}^K w_k f_k(\theta_k), \\
\text{subject to} & \theta_k = \theta, ~ k = 1, \ldots, K.
\end{array}
\end{array}
\end{equation}
我们很容易看出\eqref{eq:fl-basic-constraint}与\eqref{eq:fl-basic}这两种格式的等价性。格式\eqref{eq:fl-basic-constraint}再分布式优化中被称作共识问题(Consensus Problem)。

% 这里还应当着重指出的是，待写。。。。
