\newcommand{\urlgithub}{\url{https://github.com/wenh06/fl-sim}}
\newcommand{\urlgitee}{\url{https://gitee.com/wenh06/fl-sim}}

\section{仿真系统设计}
\addcontentsline{toe}{section}{{\thesection\ \ Design of the Simulation System}\numberline\,}
% \esection{Design of the Simulation System}
\label{sec:chap5-design}

% almost finished
% indexed

为了方便对联邦学习算法进行数值试验的对比与验证，笔者开发了一套用于单机模拟的联邦学习仿真系统\texttt{fl-sim}。联邦学习仿真系统\texttt{fl-sim}采用Python语言编写，底层的优化器，模型训练以及推理等基础功能基于深度学习框架PyTorch\cite{pytorch}构建。\texttt{fl-sim}整体结构借鉴了FedML\footnote{\url{https://github.com/FedML-AI/FedML}}\parencite{he_2020_fedml}，\texttt{FedProx}\footnote{\url{https://github.com/litian96/FedProx}}\parencite{sahu2018fedprox}以及pFL-Bench\footnote{\url{https://github.com/alibaba/FederatedScope/tree/master/benchmark/pFL-Bench}}\parencite{chen_2022_pfl_bench}等已有的一些工业应用型以及研究型的联邦学习框架。

一套设计、实现质量良好的仿真系统能够极大地促进联邦学习算法的研究，并保障其持续的进行。联邦学习仿真系统\texttt{fl-sim}的基本设计思路是基于配置文件 (或者Python类)，将数据集读取、模型参数初始化、节点分配等工作自动化。同时将节点与算法解耦合，节点需要执行的通用操作，例如通讯、获取模型参数等进行统一实现，算法相关的操作通过预留接口的方式完成。这样，利用这一套仿真系统，可以专注于联邦学习优化算法的实现与验证工作。

本章介绍的联邦学习仿真系统\texttt{fl-sim}相关的代码地址为：
\begin{itemize}
    \item GitHub: \urlgithub
    \item gitee: \urlgitee
\end{itemize}

\subsection{仿真系统的主要模块}

联邦学习仿真系统\texttt{fl-sim}主要包含以下几个模块
\begin{itemize}
    \item \texttt{data\_processing}: 联邦学习数据集数据处理模块，主要基于已有的一些研究型联邦学习框架LEAF\cite{caldas2018_leaf}，应用型联邦学习框架FedML\cite{he_2020_fedml}，以及之前的一些联邦学习领域影响力较大的工作\cite{mcmahan2017fed_avg, sahu2018fedprox, reddi2020fed_opt}提出的联邦数据集，包括图像分类的数据集MNIST\cite{Lecun_1998_mnist}, EMNIST\cite{cohen2017emnist}, Federated-EMNIST\cite{caldas2018_leaf, sahu2018fedprox}，文本情感分类数据集Sent140\cite{sent140, caldas2018_leaf},文本数据集Shakespeare (用于下一字符预测任务, Next Character Prediction)\cite{mcmahan2017fed_avg, caldas2018_leaf}等。每一个数据集以Python类的形式提供，其中打包了数据集自动下载，数据预处理(例如图像数据增强、归一化以及文本数据的向量化等操作)，为节点分配数据，创建模型训练用的数据加载器 (PyTorch DataLoader)，计算模型预测结果指标 (例如平均损失 (Mean Loss)，准确度 (Accuracy) 等) 等功能，并提供了该数据集常用模型的列表供选择使用。本报告随后的章节\S\ref{sec:chap5-datasets}将对已集成的联邦学习数据集进行更具体的介绍。
    \item \texttt{models}: 此模块主要聚合了一些已有的联邦学习文献\cite{mcmahan2017fed_avg, zhang2020fedpd, sahu2018fedprox, Ghosh_2022_cfl, he_2020_fedml}中使用过的试验模型，包括一些卷积神经网络 (Convolutional Neural Network, CNN)\index{卷积神经网络, Convolutional Neural Network, CNN}, 循环神经网络 (Recurrent Neural Network, RNN)\index{循环神经网络, Recurrent Neural Network, RNN}，多层感知机 (Multi-Layer Perceptron, MLP)\index{多层感知机, Multi-Layer Perceptron, MLP}，逻辑回归 (Logistic Regression) \index{逻辑回归, Logistic Regression}，支持向量机 (Support Vector Machine, SVM) \index{支持向量机, Support Vector Machine, SVM}等，为\texttt{data\_processing}模块中的数据集提供备选的试验模型。
    \item \texttt{optimizers}: (子节点上的) 内循环问题求解器。由于大部分试验用模型是神经网络模型，内循环问题的求解大部分基于随机梯度下降算法，包括临近子问题\eqref{eq:prox-op}~的求解，拉格朗日函数子问题\eqref{eq:al-iter-local}~的求解。大部分求解器支持方差缩减技术的应用。
    \item \texttt{algorithms}: 这一模块包含了基于联邦学习仿真系统\texttt{fl-sim}复现的部分典型的联邦学习算法，可以用作基准对比算法。联邦学习仿真系统\texttt{fl-sim}内部已复现的联邦学习算法详细信息见表~\ref{tab:algorithms}.
\end{itemize}

\input{tables/algorithms}

\texttt{fl-sim}定义了一个抽象基类 (Abstract Base Class, ABC)\footnote{相关的具体知识参阅\url{https://docs.python.org/3/library/abc.html}}\index{抽象基类, Abstract Base Class, ABC} \texttt{Node}作为子节点的类\texttt{Client}以及中心节点\texttt{Server}的公共基类，实现了所有类型的节点都要执行的公有操作：
\begin{itemize}
    \item \texttt{get\_detached\_model\_parameters}：获取当前节点分离形式 (即从PyTorch的计算图 (Computation Graph) \index{计算图, Computation Graph}) 的模型参数。
    \item \texttt{set\_parameters}：对节点的本地模型参数进行赋值。
    \item \texttt{get\_gradients}：获取当前被训练模型 (或者说目标函数) 的梯度，或者梯度的范数。
    \item \texttt{compute\_gradients}：利用给定的数据 (默认是节点上的训练集数据) 计算给定模型参数处 (默认是节点上模型当前的模型参数) 的梯度。
    \item \texttt{get\_norm}：计算模型以及一些中间变量的范数。主要用于调试联邦学习算法，例如观察算法是否陷入局部最优。
\end{itemize}
同时，以抽象方法 (Python abstractmethod) 的形式，约定所有类型的节点都必须实现的操作，包括
\begin{itemize}
    \item \texttt{communicate}: 节点间通信的操作。
    \item \texttt{update}: 节点执行迭代，更新节点上各种类型参数 (主要是更新正在训练的模型参数，以及对偶参数等) 的操作。
    \item \texttt{\_post\_init}, \texttt{required\_config\_fields}: 检查初始化是否合法相关的操作。
\end{itemize}

中心节点基类\texttt{Server}以及子节点基类\texttt{Client}分别继承\texttt{Node}基类，实现相应类型节点公有的一些操作。其中，中心节点基类\texttt{Server}实现的主要公有操作有：
\begin{itemize}
    \item \texttt{\_setup\_clients}, \texttt{\_allocate\_devices}: 为子节点分配训练数据，初始化模型参数，分配内存或显存空间等。
    \item \texttt{\_sample\_clients}: 对节点进行随机采样，以供参与当前轮次的模型训练。
    \item \texttt{add\_parameters}, \texttt{avg\_parameters}: 从收集到的子节点模型的信息更新全局模型。
    \item \texttt{train}：模型训练的主循环，即图\ref{fig:broadcast-local-update}~与图\ref{fig:agg-global-update}~所示的完整循环。同时，\texttt{train}还额外实现了数据聚合在一起的中心化训练以及无通信的子节点本地训练两种模式，供试验对比效果。
\end{itemize}
子节点基类\texttt{Client}实现的主要公有操作有：
\begin{itemize}
    \item \texttt{evaluate}：利用子节点本地数据对当前模型进行评测。
    \item \texttt{get\_all\_data}：用于快速获取子节点上包括测试集在内的所有数据。
\end{itemize}
利用联邦学习仿真系统\texttt{fl-sim}具体实现某一个算法的时候，只需要分别继承\texttt{Server}以及\texttt{Client}这两个类，将算法的主要步骤在之前提到的\texttt{communicate}, \texttt{update}等几个主要的待实现的方法中进行实现即可。

\subsection{仿真系统的易用性和可扩展性}

为了让联邦学习仿真系统\texttt{fl-sim}简单易用，我们为其设计、封装了一个命令行接口 (Command Line Interface, CLI)\index{命令行接口, Command Line Interface, CLI}, 通过读取YAML\footnote{具体介绍可见\url{https://yaml.org/}}配置文件的方式，执行相应的试验。如下是\href{https://github.com/wenh06/fl-sim/blob/master/example-configs/all-alg-fedprox-femnist.yml}{配置文件}的示例：
\begin{lstlisting}[language=yaml, caption={一份典型的联邦学习仿真系统\texttt{fl-sim}命令行接口配置文件},label={lst:fl-sim-config}]
# Example config file for fl-sim command line interface

strategy:
  matrix:
    algorithm:
    - Ditto
    - FedDR
    - FedAvg
    - FedAdam
    - FedYogi
    - FedAdagrad
    - FedProx
    - FedPD
    - FedSplit
    - IFCA
    - pFedMac
    - pFedMe
    - ProxSkip
    - SCAFFOLD
    clients_sample_ratio:
    - 0.1
    - 0.3
    - 0.7
    - 1.0
    seed:
    - 0
    - 1
    - 2
    - 3
    - 4

algorithm:
  name: ${{ matrix.algorithm }}
  server:
    num_clients: null
    clients_sample_ratio: ${{ matrix.clients_sample_ratio }}
    num_iters: 100
    p: ${{ matrix.clients_sample_ratio }}  # for FedPD, ProxSkip
    lr: 0.003  # for SCAFFOLD, FedOpt (FedAdam, FedYogi, FedAdagrad, etc.), this parameter is quite sensitive
    num_clusters: 10  # for IFCA
    log_dir: all-alg-fedprox-femnist
    tag: sample_ratio_${{ matrix.clients_sample_ratio }}-seed_${{ matrix.seed }}
  client:
    lr: 0.03
    num_epochs: 10
    batch_size: null  # null for default batch size
    scheduler:
      name: step  # StepLR
      step_size: 1
      gamma: 0.99
dataset:
  name: FedProxFEMNIST
  datadir: null  # default dir
  transform: none  # none for static transform (only normalization, no augmentation)
model:
  name: cnn_femmist_tiny
seed: ${{ matrix.seed }}
\end{lstlisting}
其中，
\begin{itemize}
    \item \texttt{strategy}字段定义了执行``超参数网格搜索''的策略，在这个例子中，我们对列出的14种算法\texttt{Ditto}、\texttt{FedDR}、\texttt{FedAvg}、\texttt{FedAdam}、\texttt{FedYoji}、\texttt{FedAdagrad}、\texttt{FedProx}、\texttt{FedPD}、\texttt{FedSplit}、\texttt{IFCA}、\texttt{pFedMac}、\texttt{pFedMe}、\texttt{ProxSkip}、\texttt{SCAFFOLD}都执行子节点参与率分别为$0.1, 0.3, 0.7, 1.0$的4组试验，每组试验使用不同的随机数种子重复5次，共计280次试验。
    \item \texttt{algorithm}字段下的\texttt{name}子字段指定了单次试验的联邦学习算法，\texttt{server}以及\texttt{client}子字段分别指定了中心节点以及子节点的超参数设置。例如，\texttt{num\_clients}指定了参与联邦学习训练总的子节点数目，置为空值 (\texttt{null}) 表示使用相关数据集默认的子节点数目；\texttt{clients\_sample\_ratio}指定了参与每一轮训练的子节点的比例。
    \item \texttt{dataset}以及\texttt{model}字段分别指定了单次试验使用的联邦学习数据集以及试验模型。
    \item \texttt{seed}字段指定了试验的随机种子。
\end{itemize}

联邦学习仿真系统\texttt{fl-sim}也有极强的可扩展性。\texttt{fl-sim}系统内部设计了如下的几个``注册''装饰器 (Python decorator\footnote{具体介绍可见\url{https://peps.python.org/pep-0318/}}):
\begin{itemize}
    \item \verb|register_algorithm| (在模块 \href{https://github.com/wenh06/fl-sim/blob/master/fl_sim/algorithms/_register.py}{\texttt{fl\_sim.algorithms}} 中实现)
    \item \verb|register_optimizer| (在模块 \href{https://github.com/wenh06/fl-sim/blob/master/fl_sim/optimizers/_register.py}{\texttt{fl\_sim.optimizers}} 中实现)
    \item \verb|register_fed_dataset| (在模块 \href{https://github.com/wenh06/fl-sim/blob/master/fl_sim/data_processing/_register.py}{\texttt{fl\_sim.data\_processing}} 中实现)
\end{itemize}
使用者可以利用这些装饰器装饰自行实现的联邦学习算法，子节点上 (内层问题) 的求解器，以及数据集相关的Python类，同时将配置文件中的algorithm, dataset等字段的name子字段配置为相应的文件路径即可。
