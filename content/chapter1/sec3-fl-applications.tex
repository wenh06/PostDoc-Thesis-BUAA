\section{联邦学习的应用与发展前景}
\addcontentsline{toe}{section}{{\thecurrentchapter .3\ \ Applications and Future Perspective of Federal Learning}\numberline\,}
\label{sec:chap1-fl-applications}

% finished
% indexed

尽管联邦学习这一概念被提出\cite{mcmahan2017fed_avg}的时间不长，但是联邦学习已经有了不少实际的应用。我们这里仅列举一些比较重要的例子。
\begin{itemize}
    \item 首先是金融领域，联邦学习在财会\cite{Schreyer_2022_fl_audits}，信贷风控\cite{Imteaj_2022_fl}，反欺诈\cite{Lv_2021_fl}，防范金融犯罪\cite{Toyotaro_2019_fl}等各个方面都有了实际的应用。这其中最引人注目的当属我国微众银行在这一领域的一系列前沿以及开创性的研究\cite{Yang_2019_VFL, liu_2020_transfer_fl, vfl}，并以真正落地形成工业级产品的联邦学习应用框架FATE\cite{liu_2021_fate_fl}.
    \item 联邦学习在智慧医疗领域也有颇多成功应用的案例\cite{rauniyar2022_fl_medical, Antunes_2022_fl_healthcare}。从电子健康档案 (Electronic Health Records, EHR) 处理\cite{Brisimi_2018_fl_ehr}，医学影像处理\cite{Li_2020_fl_mri}，到新冠 (COVID-19) 等流行病的研究\cite{Dayan_2021_fl_covid}，都有联邦学习的应用案例。医学因为其数据隐私性的严格要求，同时又有市场的巨大需求驱动，是联邦学习非常适宜的应用领域，同时也可能是相关研究最活跃、应用落地最多的领域之一。
    \item 移动设备、物联网领域：这是联邦学习发轫\cite{mcmahan2017fed_avg}的领域，也是大规模跨设备 (Cross-Device) 场景最常见的领域，应用也从最一开始的安卓设备键盘辅助输入扩展到了移动设备的语音处理\cite{Leroy_2019_fl_ks}，人体活动识别 (Human Activity Recognition)\cite{Sozinov_2018_fl_human}，乃至人口流动预测 (Human Mobility Prediction)\cite{feng_2020_fl_pmf} 等问题。因为隐私性以及模型个性化 (Model Personalization) 等要求，很多时候联邦学习甚至是解决问题的唯一选择。
\end{itemize}

除了以上列举的一些领域外，联邦学习的应用还逐渐扩大到了智慧城市 (Smart City)\cite{Zheng_2021_fl_smart_city}、纳米材料研究\cite{Huang_2022_fl_physics}等全新的领域。可以说，联邦学习的应用场景相较于它被提出时已经得到了极大的丰富，用于仿真试验的数据集也有了很多积累。同时，也涌现出了像FedML\cite{he_2020_fedml}，FederatedScope\cite{Xie_2023_fl_scope}, TensorFlow Federated\cite{tensorflow}，FedSim\cite{wu_2021_fedsim}，PySyft\cite{ryffel_2018_pysyft}，以及之前提到的FATE\cite{liu_2021_fate_fl}等多个有不同侧重点的联邦学习软件包，为联邦学习的研究与应用落地，都提供了极大的便利。然而目前联邦学习在理论以及实际应用上，还有不少问题没有完善的解决，仍然面临着诸多的挑战\cite{kairouz2019advances_fl, Li_2020_fl_challenges}。综述性的文章\parencite{Li_2020_fl_challenges, Wu_2020_iot_fl}将其总结为了如下几个核心的问题：
\begin{itemize}
\item 通信 (Communication) 开销。联邦学习往往有数量庞大的参与方，这些数量庞大的参与方可能在地理上分布极广且不均衡，这在跨设备 (Cross-Device) 的场景尤为常见。联邦学习各个参与方为了达到协同训练模型的目的，需要传输一些信息。这种情况下，节点之间的通信带宽是较低的，有时候节点之间用于通信的时长会远高于节点本地执行模型训练的计算时长。这就带来了极高的通信成本，使得通信成为了联邦学习的关键性瓶颈之一。联邦学习研究人员为处理这个问题提出了多项技术，如压缩传输\cite{seide2014_1bitsgd}，异步更新\cite{tran2021feddr}，``跳步''\cite{proxskip, zhang2020fedpd}，乃至将联邦学习节点网络进行分层组成超图\cite{t2020pfedme}等。
\item 数据隐私的保护。数据的隐私性要求是联邦学习被提出的主要原因之一，也是需要考虑的基本问题。经典的联邦学习通过共享模型更新，而不是原始数据，用作保护每个参与方数据的基本手段。然而，在整个训练过程中传递模型更新可能会向第三方或中央服务器泄露敏感信息，特别是梯度信息的使用存在着使得第三方反推原始数据的可能\cite{zhu2019deep_leakage}。尽管可以使用差分隐私\cite{Dwork_2008_DP}等工具增强联邦学习对隐私的保护能力，但这些方法通常以降低模型性能或系统效率为代价。如何权衡隐私的保护与模型的性能，进行取舍，乃至从原理上进行改进，是联邦学习的一个相当大的挑战。
\item 系统异质性 (Systems Heterogeneity)\index{系统异质性, Systems Heterogeneity}。联邦学习的各个参与方在计算资源 (CPU和内存)、网络条件 (3G、4G、5G和Wi-Fi) 等硬件条件是差别极大的，因此联邦学习参与方的设备在存储、计算和通信等几个方面的能力会大不相同。此外，设备的性能差异和一些系统无关的约束，例如私人手机作为参与方在工作时间无暇参与联邦学习；由于网络连接的不稳定性或设备能量限制等，有参与方设备在联邦学习训练的中途退出也是会发生的。这些系统上的特性使联邦学习的算法与系统设计需要在应对掉队者 (Straggler)，提高容错能力 (Fault Tolerance) 等方面有一定的考虑。
\item 统计异质性 (Statistical Heterogeneity)\index{统计异质性, Statistical Heterogeneity}。通常参与方的设备产生和收集数据的方式是有高度非一致性的。这种数据生成方式因为不满足分布式优化中经常使用的独立同分布 (Independent and Identically Distributed, I.I.D.)\index{独立同分布, Independent and Identically Distributed, I.I.D.} 假设，从而可能在问题建模、算法收敛性(无论是理论分析上还是实际应用上)等方面带来困难。文献\cite{kairouz2019advances_fl}对联邦学习参与方之间的数据的统计异构性做了详细的分类。我们沿用上一小节的记号，用
\begin{equation}
\label{eq:dist_decomp}
\mathcal{D}_k(x, y) = \mathcal{D}_k(y | x) \mathcal{D}_k(x) = \mathcal{D}_k(x | y) \mathcal{D}_k(y)
\end{equation}
表示联邦学习参与方$k$上的训练数据的概率分布，其中$\mathcal{D}_k(x),$ $\mathcal{D}_k(y)$分别表示样本数据特征的边缘分布以及标签的边缘分布；$\mathcal{D}_k(y | x),$ $\mathcal{D}_k(x | y)$表示条件分布。

具体来说，根据$\mathcal{D}_k(x),$ $\mathcal{D}_k(y),$ $\mathcal{D}_k(x | y),$ $\mathcal{D}_k(y | x)$的由参与方$k$的不同而带来的差别，这些统计异质性体现为
\begin{itemize}
    \item 特征分布偏斜 (Feature Distribution Skew)\index{特征分布偏斜, Feature Distribution Skew}，又称协变量偏移 (Covariate Shift)\index{协变量偏移, Covariate Shift}。这种统计的异质性是由于特征的 (边缘) 分布$\mathcal{D}_k(x)$在不同的参与方$K$之间不是同分布的。例如手写字体识别，不同的人写出的同一个字的字形会有区别；又例如语音识别，不同的人说同一段话也可能会有口音的差别。
    \item 标签分布偏斜 (Label Distribution Skew)\index{标签分布偏斜, Label Distribution Skew}，又称先验概率偏移 (Prior Probability Shift)\index{先验概率偏移, Prior Probability Shift}。这种统计的异质性是由于标签的 (边缘) 分布$\mathcal{D}_k(y)$不是同分布的，很多时候与样本的地域分布有较强的的关联。例如橡胶树、棕榈树等基本不会生长在高维度地区，而针叶乔木在热带地区也是极为罕见的。如果某个联邦学习系统用于植物的图像自动识别，参与方在热带、寒带地区都有分布，则很可能会发生如上的先验概率偏移现象。
    \item 概念偏移 (Concept Shift)\index{概念偏移, Concept Shift}，即条件分布$\mathcal{D}_k(x | y)$与$\mathcal{D}_k(y | x)$的在不同参与方$k$之间的差异性导致的。通俗来说，就是同一概念(即标签$y$)，在不同参与方$k$上对应的事物 (即特征$x$) 可能差异极大，例如某些地区的``桥''只有形态稍有差异的简易木桥，一些地区古朴的拱式桥占多数，而又有一些区域有大量的宏伟的斜拉桥；或是同一事物 (即特征$x$) 在不同的参与方对应差别巨大的概念 (即标签$y$)，例如同样是吸食大麻的行为，在某些地区可能被认为只是一种中性的个人爱好，而在另一些地区被认为是非常恶劣的犯罪行为。
    \item 数量偏斜 (Quantity Skew)\index{数量偏斜, Quantity Skew}。联邦学习参与方持有的数据量可能差别很大，甚至达到数量级的差异。这种情况下，公平性 (Fairness) 以及训练的效率等问题是不可忽视的。
\item 模型异质性 (Model Heterogeneity)\index{模型异质性, Model Heterogeneity}。很多时候，子节点由于之前提到的系统异质性的原因，导致在模型结构 (Model Architecture)，尤其是深度学习模型结构，的选取上会有不同。例如计算资源不足的子节点会倾向去采用轻量级的模型，而计算资源充足的子节点可能会使用稍大的模型以提高模型准确率。在联邦学习参与方模型结构有差异的场景下，这些模型是无法使用加权平均\cite{mcmahan2017fed_avg}的方式进行模型聚合的。如何使得这些有差异的模型，在满足联邦学习隐私性要求的情况下进行知识的共享，目前仍是未解决的困难问题。
\end{itemize}
在真实的联邦学习应用场景中，这几种统计上的异质性都可能会出现，会让情况变得及其复杂。因为这种统计异构性的存在，尽管经典的联邦学习问题旨在学习共享的全局模型，许多研究者投入到个性化联邦学习的研究中，这也是本报告的研究重点之一。
\end{itemize}

关于这几大挑战，还有为数众多的公开问题未得到解决。例如联邦学习在接近实际情况 (即目标函数非凸，再叠加上统计异质性与系统异构性等复杂因素) 下，优化算法的设计及其理论收敛性以及收敛率；个性化联邦学习的建模，优化算法迭代格式；传统优化算法，例如算子分裂算法、交替方向乘子法，在联邦学习的范畴以及框架内的适配改造与应用；无中心的全分布式联邦学习的建模、优化算法设计、收敛性分析。这些都是联邦学习这一研究领域在未来的一段时间内要进行研究探索的重要问题，本报告将会就其部分内容进行深入的讨论与研究。
