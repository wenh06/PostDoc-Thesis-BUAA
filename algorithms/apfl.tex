\begin{algorithm}[ht]
% \SetAlgoNoLine
% \DontPrintSemicolon
\SetKwInOut{Input}{Input}
\Input{mixture weights $\alpha_1, \ldots, \alpha_K,$ synchronization gap $\tau$}
{\bfseries Initiation:}\;
\Indp
    {\bfseries Init server:} global model parameters $\theta^{(0)} \in \R^d,$ random set of clients $S^{(t)} \subseteq [K]$\;
    {\bfseries Init clients:} local model parameters $\omega_k^{(0)} \in \R^d, ~ \theta_k^{(0)} \gets \theta^{(0)}, ~ \forall k \in [K]$\;
    {\bfseries Constants:} $\kappa \gets \frac{L}{\mu},$ $a \gets \max\{128\kappa, \tau\}$\;
\Indm
\For{each round $t = 0, 1, \cdots, T-1$}{
    \For{each client $k \in \mathcal{S}^{(t)}$ {\bfseries in parallel}}{
        mixture model $\bar{\omega}_k^{(t)} \gets \alpha_k \omega_k^{(t)} + (1-\alpha_k) \theta_k^{(t)}$\;
        learning rate $\eta^{(t)} \gets \frac{16}{\mu(t+a)}$\;
        $\theta_k^{(t+1)} \gets \theta^{(t)} - \eta \nabla f_k(\theta^{(t)})$\;
        $\omega_k^{(t+1)} \gets \omega_k^{(t)} - \eta \nabla f_k(\bar{\omega}_k^{(t)})$\;
    }
    \uIf{$t$ not divides synchronization gap $\tau$}{
        {\bfseries Server updates}: $\mathcal{S}^{(t+1)} \gets \mathcal{S}^{(t)}$\;
    }
    \Else{
        each client $k \in \mathcal{S}^{(t)}$ sends $\theta_k^{(t+1)}$ to server\;
        {\bfseries Server updates}:\;
        \Indp
        $\theta^{(t+1)} \gets \frac{1}{\# \mathcal{S}^{(t)}} \theta_k^{(t)}$\;
        $\mathcal{S}^{(t+1)} \gets$ (random set of clients) $\subseteq [K]$\;
        broadcast $\theta^{(t+1)}$ to clients $k \in S^{(t+1)}$\;
        \Indm
    }
final personalized model: $\hat{\omega}_k \gets \frac{1}{S_T}\sum\limits_{t=1}^{T} p_t \left( \alpha_k \omega_k^{(t)} + (1-\alpha_k)\frac{1}{\#\mathcal{S}^{(t-1)}}\sum\limits_{k\in\mathcal{S}^{(t-1)}}\theta_k^{(t)} \right)$\;
final global model: $\hat{\theta} \gets \frac{1}{S_T}\sum\limits_{t=1}^{T} \frac{p_t}{\#\mathcal{S}^{(t)}} \sum\limits_{k\in\mathcal{S}^{(t-1)}}\theta_k^{(t)}$\;
where $p_t = (t+a)^2, S_T = \sum\limits_{t=1}^{T}p_t$\;
}
\caption{算法\texttt{APFL}\cite{deng2020_apfl}的伪代码}
\label{algo:apfl}
\end{algorithm}
