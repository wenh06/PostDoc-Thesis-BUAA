\begin{algorithm}[ht]
% \SetAlgoNoLine
% \DontPrintSemicolon
\SetKwInOut{Input}{Input}
\Input{penalty coefficient $\lambda,$ learning rate $\eta,$ $\beta$}
{\bfseries Initiation:}\;
\Indp
    {\bfseries Init server:} global model parameters $\theta^{(0)} \in \R^d$\;
\Indm
\For{each round $t = 0, \cdots, T-1$}{
    Server sends $\theta^{(t)}$ to all clients\;
    \For{each client $k = 1, \cdots, K$ in parallel}{
        $\theta_{k}^{(t, 0)} = \theta^{(t)}$\;
        \For{$r = 0,\cdots, R-1$}{
            sample a mini-batch $b_r$\;
            find an approximate $\theta_k(\theta_{k}^{(t, r)}) \approx \argmin\limits_{\theta_k} \left\{ \ell_k(\theta_k; b_r) + \frac{\lambda}{2} \left\lVert \theta_k - \theta_{k}^{(t, r)} \right\rVert^2 \right\}$\;
            client (local) update $\theta_{k}^{(t, r+1)} \gets \theta_{k}^{(t, r)} - \eta \lambda \left( \theta_{k}^{(t, r)} - \theta_k(\theta_{k}^{(t, r)}) \right)$\;
        }
        Server uniformly samples a subset of clients $\mathcal{S}^{(t)}$,\;
        each client in $\mathcal{S}^{(t)}$ sends the local $\theta_{k}^{(t, R)}$ to the server\;
    }
    Sever update $\theta^{(t+1)} \gets (1-\beta)\theta^{(t)} + \frac{\beta}{\# \mathcal{S}^{(t)}} \sum\limits_{k \in \mathcal{S}^{(t)}} \theta_{k}^{(t, R)}$
}
\caption{\texttt{pFedMe}\cite{t2020pfedme}算法伪代码}
\label{algo:pfedme}
\end{algorithm}
